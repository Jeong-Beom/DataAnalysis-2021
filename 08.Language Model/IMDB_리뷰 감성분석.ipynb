{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# IMDB 영화 리뷰 분석\r\n",
    "with open('C:\\\\Workspace\\\\python\\\\Data_Science\\\\dataA\\\\labeledTrainData.tsv', encoding = 'UTF-8')as f:\r\n",
    "    file = f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "len(file)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33550296"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "df = pd.read_csv('C:\\\\Workspace\\\\python\\\\Data_Science\\\\dataA\\\\labeledTrainData.tsv', sep = '\\t', quoting = 3)\r\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df.review[0][:1000]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# <br /> 태그는 공백으로 전환\r\n",
    "df['review'] = df.review.str.replace('<br />', ' ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 구둣점, 숫자 제거 --> 영어 이외의 문자는 공백으로 변환\r\n",
    "import re\r\n",
    "df['review'] = df.review.apply(lambda x : re.sub('[^A-Za-z]', ' ', x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "df.review[0][:1000]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay   Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him   The actual feature film bit when it finally starts is only on for  '"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df.sentiment.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# 학습 및 테스트 데이터 셋으로 분리\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    df.review, df.sentiment, test_size = 0.2, # 훈련용 20000개, 테스트용 5000개\r\n",
    "    stratify = df.sentiment,random_state = 2021\r\n",
    ")\r\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000,), (5000,), (20000,), (5000,))"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# 텍스트 변환 - CounterVectorizer, ngram_range 활용\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#이렇게 변환하면 안됨.\r\n",
    "cvect1 = CountVectorizer(stop_words = 'english')\r\n",
    "X_train_cv1 = cvect1.fit_transform(X_train)\r\n",
    "X_test_cv1 = cvect1.fit_transform(X_test)\r\n",
    "X_train_cv1.shape, X_test_cv1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000, 66971), (5000, 37187))"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# train, test data set에 있는 동일한 단어에 대해서 동일한 값으로 변환하기 위해 반드시 아래와 같이 해야함\r\n",
    "cvect1 = CountVectorizer(stop_words = 'english')\r\n",
    "cvect1.fit(X_train)\r\n",
    "X_train_cv1 = cvect1.transform(X_train)\r\n",
    "X_test_cv1 = cvect1.transform(X_test)\r\n",
    "X_train_cv1.shape, X_test_cv1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000, 66971), (5000, 66971))"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# 로지스틱 회귀모델 연습\r\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 객체 생성 및 훈련 - 훈련 데이터의 X와 y 모두필요\r\n",
    "lr1 = LogisticRegression(max_iter = 500)\r\n",
    "%time lr1.fit(X_train_cv1, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 3.9 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# 테스트 데이터에 대해 예측\r\n",
    "pred1 = lr1.predict(X_test_cv1)\r\n",
    "pred1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "cvect2 = CountVectorizer(stop_words = 'english', ngram_range = (1, 2))\r\n",
    "cvect2.fit(X_train)\r\n",
    "X_train_cv2 = cvect2.transform(X_train)\r\n",
    "X_test_cv2 = cvect2.transform(X_test)\r\n",
    "X_train_cv2.shape, X_test_cv2.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000, 1461350), (5000, 1461350))"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "lr2 = LogisticRegression(max_iter = 500)\r\n",
    "%time lr2.fit(X_train_cv2, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 31 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "pred2 = lr2.predict(X_test_cv2)\r\n",
    "pred2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# TfidVectorizer, ngram_range = (1, 1)\r\n",
    "tvect1 = TfidfVectorizer(stop_words = 'english')\r\n",
    "tvect1.fit(X_train)\r\n",
    "X_train_tv1 = tvect1.transform(X_train)\r\n",
    "X_test_tv1 = tvect1.transform(X_test)\r\n",
    "X_train_tv1.shape, X_test_tv1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000, 66971), (5000, 66971))"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "lr3 = LogisticRegression(max_iter = 500)\r\n",
    "%time lr3.fit(X_train_tv1, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "pred3 = lr3.predict(X_test_tv1)\r\n",
    "pred3"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# TfidVectorizer, ngram_range = (1, 2)\r\n",
    "tvect2 = TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))\r\n",
    "tvect2.fit(X_train)\r\n",
    "X_train_tv2 = tvect2.transform(X_train)\r\n",
    "X_test_tv2 = tvect2.transform(X_test)\r\n",
    "X_train_tv2.shape, X_test_tv2.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((20000, 1461350), (5000, 1461350))"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "lr4 = LogisticRegression(max_iter = 500)\r\n",
    "%time lr4.fit(X_train_tv2, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 9.45 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "pred4 = lr4.predict(X_test_tv2)\r\n",
    "pred4"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 평가\r\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "score1 = accuracy_score(y_test, pred1)\r\n",
    "score2 = accuracy_score(y_test, pred2)\r\n",
    "print(f'{score1} --> {score2}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8832 --> 0.8914\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "score3 = accuracy_score(y_test, pred3)\r\n",
    "score4 = accuracy_score(y_test, pred4)\r\n",
    "print(f'{score3} --> {score4}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.893 --> 0.883\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# 비지도 학습 기반 감성분석\r\n",
    "# 감성어휘사전\r\n",
    "import nltk\r\n",
    "nltk.download('vader_lexicon')\r\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
    "sanalyer = SentimentIntensityAnalyzer()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Bestc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "senti_score = sanalyer.polarity_scores(df.review[0])\r\n",
    "senti_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# compund score 값이 0.1 보다 크면 긍정(1), 낮으면 부정(0)\r\n",
    "def get_sentiment(sanalyer, review, threshold):\r\n",
    "    score = sanalyer.polarity_scores(review)\r\n",
    "    compound_score = score['compound']\r\n",
    "    final_score = 1 if compound_score >= threshold else 0\r\n",
    "    return final_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "df['vader_pred'] = df.review.apply(lambda x: get_sentiment(sanalyer, x, 0.1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# 평가, real y - df.review.apply(lambda x: get_sentiment(sanalyzer, x, 0.1))\r\n",
    "accuracy_score(df.sentiment, df.vader_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.69556"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "for threshold in [0, 0.1, 0.2, 0.3]:\r\n",
    "    df['vader_pred'] = df.review.apply(lambda x: get_sentiment(sanalyer, x, threshold))\r\n",
    "    score = accuracy_score(df.sentiment, df.vader_pred)\r\n",
    "    print(f'threhold값 {threshold} : {score}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "threhold값 0 : 0.69104\n",
      "threhold값 0.1 : 0.69556\n",
      "threhold값 0.2 : 0.69952\n",
      "threhold값 0.3 : 0.70264\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fe3bab233825460445dbfeea6dcd52ef5815a3fa13c858fea07ac830aa383284"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}