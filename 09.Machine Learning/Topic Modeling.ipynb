{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 토픽모델링 : 단어로부터 주제를 유추해내는 방법\r\n",
    "from sklearn.datasets import fetch_20newsgroups\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "news = fetch_20newsgroups(subset = 'all', random_state = 2021, remove = ('headrs', 'footers', 'qoutes'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "df = pd.DataFrame({'article' : news.data})\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18846, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "df.article = df.article.str.replace('[^A-Za-z]', ' ')\r\n",
    "df.article = df.article.apply(lambda x: ' '.join(w.lower() for w in x.split() if len(w) > 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<ipython-input-30-d1cfcec8897b>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.article = df.article.str.replace('[^A-Za-z]', ' ')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bestc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "stop_words = stopwords.words('english')\r\n",
    "df['article']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        from dagibbs quantum david gibbs subject count...\n",
       "1        from kehoe netcom thomas david kehoe subject s...\n",
       "2        from rexlex fnal fnal subject assurance hell o...\n",
       "3        from scss mark riordan subject list large inte...\n",
       "4        from adam stratus mark adam subject space food...\n",
       "                               ...                        \n",
       "18841    from choman rajeesh charles stanley homan subj...\n",
       "18842    from jaeger buphy gregg jaeger subject more ru...\n",
       "18843    from tedebear leland stanford theodore chen su...\n",
       "18844    from phil howtek phil hunt subject motherboard...\n",
       "18845    from mwhaefne infonode ingr mark haefner subje...\n",
       "Name: article, Length: 18846, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "tokenized_doc = df.article.apply(lambda x: [w for w in x.split() if w not in stop_words])\r\n",
    "tokenized_doc[:5]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [dagibbs, quantum, david, gibbs, subject, coun...\n",
       "1    [kehoe, netcom, thomas, david, kehoe, subject,...\n",
       "2    [rexlex, fnal, fnal, subject, assurance, hell,...\n",
       "3    [scss, mark, riordan, subject, list, large, in...\n",
       "4    [adam, stratus, mark, adam, subject, space, fo...\n",
       "Name: article, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from gensim import corpora\r\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\r\n",
    "corpus = [dictionary]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\r\n",
    "print(corpus[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 2), (3, 2), (4, 1), (5, 2), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 3), (14, 2), (15, 1), (16, 3), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 4), (28, 1), (29, 2), (30, 2), (31, 3), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 3), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "dictionary[0], dictionary[1], dictionary[2], dictionary[3]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('allowed', 'answer', 'article', 'bars')"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import gensim\r\n",
    "from gensim.models.ldamodel import LdaModel\r\n",
    "NUM_TOPICS = 20"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(\r\n",
    "    corpus, num_topics = NUM_TOPICS,\r\n",
    "    id2word = dictionary, passes = 20\r\n",
    ")\r\n",
    "topics = ldamodel.print_topics(num_words = 4)\r\n",
    "for topic in topics:\r\n",
    "    print(topic)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, '0.013*\"myers\" + 0.010*\"wire\" + 0.010*\"ground\" + 0.009*\"audio\"')\n",
      "(1, '0.014*\"writes\" + 0.014*\"subject\" + 0.014*\"organization\" + 0.013*\"lines\"')\n",
      "(2, '0.019*\"writes\" + 0.019*\"article\" + 0.016*\"lines\" + 0.014*\"subject\"')\n",
      "(3, '0.046*\"colorado\" + 0.012*\"boulder\" + 0.008*\"spot\" + 0.008*\"harris\"')\n",
      "(4, '0.010*\"available\" + 0.009*\"file\" + 0.008*\"data\" + 0.008*\"image\"')\n",
      "(5, '0.037*\"stanford\" + 0.021*\"uchicago\" + 0.016*\"andy\" + 0.014*\"midway\"')\n",
      "(6, '0.052*\"drive\" + 0.030*\"scsi\" + 0.019*\"disk\" + 0.017*\"hard\"')\n",
      "(7, '0.041*\"lines\" + 0.041*\"subject\" + 0.040*\"organization\" + 0.023*\"posting\"')\n",
      "(8, '0.023*\"game\" + 0.022*\"team\" + 0.015*\"games\" + 0.012*\"hockey\"')\n",
      "(9, '0.012*\"people\" + 0.012*\"would\" + 0.008*\"think\" + 0.007*\"know\"')\n",
      "(10, '0.057*\"space\" + 0.045*\"nasa\" + 0.016*\"earth\" + 0.013*\"moon\"')\n",
      "(11, '0.033*\"israel\" + 0.025*\"state\" + 0.018*\"jews\" + 0.018*\"israeli\"')\n",
      "(12, '0.027*\"windows\" + 0.012*\"window\" + 0.011*\"problem\" + 0.009*\"subject\"')\n",
      "(13, '0.010*\"writes\" + 0.008*\"article\" + 0.007*\"medical\" + 0.007*\"health\"')\n",
      "(14, '0.025*\"writes\" + 0.023*\"article\" + 0.018*\"organization\" + 0.018*\"subject\"')\n",
      "(15, '0.011*\"would\" + 0.010*\"like\" + 0.009*\"writes\" + 0.008*\"lines\"')\n",
      "(16, '0.009*\"said\" + 0.009*\"people\" + 0.009*\"armenian\" + 0.007*\"turkish\"')\n",
      "(17, '0.010*\"government\" + 0.009*\"would\" + 0.006*\"people\" + 0.005*\"president\"')\n",
      "(18, '0.011*\"writes\" + 0.010*\"lines\" + 0.010*\"organization\" + 0.010*\"subject\"')\n",
      "(19, '0.030*\"columbia\" + 0.022*\"pitt\" + 0.018*\"canada\" + 0.015*\"gordon\"')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 훈련결과 시각화\r\n",
    "import pyLDAvis.gensim\r\n",
    "pyLDAvis.enable_notebook()\r\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\r\n",
    "pyLDAvis.display(vis)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pyLDAvis.save.html(vis, 'news_group_20.html')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, topic_list in enumerate(ldamodel[corpus]):\r\n",
    "    if i == 5:\r\n",
    "        break\r\n",
    "    print(i, '번째 문서의 topic 비율은', topic_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 번째 문서의 topic 비율은 [(9, 0.070974), (13, 0.7581079), (19, 0.16124886)]\n",
      "1 번째 문서의 topic 비율은 [(2, 0.037462547), (3, 0.36621648), (7, 0.07289094), (10, 0.22563429), (11, 0.03912408), (12, 0.043068886), (13, 0.05493504), (15, 0.043312714), (16, 0.085189976), (18, 0.028148508)]\n",
      "2 번째 문서의 topic 비율은 [(0, 0.029965961), (2, 0.04195987), (11, 0.09558341), (13, 0.77332354), (17, 0.010226148)]\n",
      "3 번째 문서의 topic 비율은 [(1, 0.1202197), (3, 0.015165395), (4, 0.010708628), (10, 0.07779404), (11, 0.04722612), (14, 0.53794676), (15, 0.046335116), (16, 0.020760257), (19, 0.10001559)]\n",
      "4 번째 문서의 topic 비율은 [(0, 0.02753245), (3, 0.22443521), (9, 0.30767712), (12, 0.023613915), (13, 0.26246876), (16, 0.09432114), (18, 0.05219759)]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\r\n",
    "    topic_table = pd.DataFrame()\r\n",
    "\r\n",
    "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\r\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\r\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \r\n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\r\n",
    "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\r\n",
    "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \r\n",
    "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\r\n",
    "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\r\n",
    "\r\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\r\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\r\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\r\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\r\n",
    "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\r\n",
    "            else:\r\n",
    "                break\r\n",
    "    return(topic_table)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "topictable = make_topictable_per_doc(ldamodel, corpus)\r\n",
    "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\r\n",
    "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\r\n",
    "topictable[:10]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Bestc\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문서 번호</th>\n",
       "      <th>가장 비중이 높은 토픽</th>\n",
       "      <th>가장 높은 토픽의 비중</th>\n",
       "      <th>각 토픽의 비중</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>[(9, 0.07096184), (13, 0.758099), (19, 0.16126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>[(2, 0.037472274), (3, 0.3662837), (7, 0.07291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>[(0, 0.02996597), (2, 0.04195992), (11, 0.0955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>[(1, 0.1202205), (3, 0.015164034), (4, 0.01070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>[(0, 0.027533242), (3, 0.22448367), (9, 0.3076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>[(0, 0.2628206), (1, 0.040870313), (2, 0.03836...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>[(1, 0.025239168), (3, 0.04897583), (10, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>[(3, 0.017460966), (11, 0.5364719), (13, 0.328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>[(9, 0.5572675), (10, 0.34225678), (12, 0.0557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4192</td>\n",
       "      <td>[(2, 0.053191822), (3, 0.41915387), (6, 0.0183...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
       "0      0          13.0        0.7581   \n",
       "1      1           3.0        0.3663   \n",
       "2      2          13.0        0.7733   \n",
       "3      3          14.0        0.5379   \n",
       "4      4           9.0        0.3077   \n",
       "5      5           0.0        0.2628   \n",
       "6      6          19.0        0.3305   \n",
       "7      7          11.0        0.5365   \n",
       "8      8           9.0        0.5573   \n",
       "9      9           3.0        0.4192   \n",
       "\n",
       "                                            각 토픽의 비중  \n",
       "0  [(9, 0.07096184), (13, 0.758099), (19, 0.16126...  \n",
       "1  [(2, 0.037472274), (3, 0.3662837), (7, 0.07291...  \n",
       "2  [(0, 0.02996597), (2, 0.04195992), (11, 0.0955...  \n",
       "3  [(1, 0.1202205), (3, 0.015164034), (4, 0.01070...  \n",
       "4  [(0, 0.027533242), (3, 0.22448367), (9, 0.3076...  \n",
       "5  [(0, 0.2628206), (1, 0.040870313), (2, 0.03836...  \n",
       "6  [(1, 0.025239168), (3, 0.04897583), (10, 0.029...  \n",
       "7  [(3, 0.017460966), (11, 0.5364719), (13, 0.328...  \n",
       "8  [(9, 0.5572675), (10, 0.34225678), (12, 0.0557...  \n",
       "9  [(2, 0.053191822), (3, 0.41915387), (6, 0.0183...  "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fe3bab233825460445dbfeea6dcd52ef5815a3fa13c858fea07ac830aa383284"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}