{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset.zip',\n",
       " 'Dataset_01.csv',\n",
       " 'Dataset_02.csv',\n",
       " 'Dataset_03.csv',\n",
       " 'Dataset_04.csv',\n",
       " 'Dataset_05.csv',\n",
       " 'Dataset_05_item_list.csv',\n",
       " 'Dataset_05_Mart_POS.csv',\n",
       " 'Dataset_06.csv',\n",
       " 'Dataset_07.csv',\n",
       " 'Dataset_08.csv',\n",
       " 'Dataset_09.csv',\n",
       " 'Dataset_10.csv',\n",
       " 'Dataset_11.csv',\n",
       " 'Dataset_12.csv',\n",
       " 'Dataset_13_test.csv',\n",
       " 'Dataset_13_train.csv',\n",
       " 'Dataset_14.csv',\n",
       " 'Dataset_15_item_list.csv',\n",
       " 'Dataset_15_Mart_POS.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'C:/Workspace/python/Data_Science/dataA/ProDS특강/'\n",
    "file_list = os.listdir(PATH)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social_Media</th>\n",
       "      <th>Influencer</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.566231</td>\n",
       "      <td>2.907983</td>\n",
       "      <td>Mega</td>\n",
       "      <td>54.732757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>9.237765</td>\n",
       "      <td>2.409567</td>\n",
       "      <td>Mega</td>\n",
       "      <td>46.677897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>15.886446</td>\n",
       "      <td>2.913410</td>\n",
       "      <td>Mega</td>\n",
       "      <td>150.177829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.0</td>\n",
       "      <td>30.020028</td>\n",
       "      <td>6.922304</td>\n",
       "      <td>Mega</td>\n",
       "      <td>298.246340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.437408</td>\n",
       "      <td>1.405998</td>\n",
       "      <td>Micro</td>\n",
       "      <td>56.594181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TV      Radio  Social_Media Influencer       Sales\n",
       "0  16.0   6.566231      2.907983       Mega   54.732757\n",
       "1  13.0   9.237765      2.409567       Mega   46.677897\n",
       "2  41.0  15.886446      2.913410       Mega  150.177829\n",
       "3  83.0  30.020028      6.922304       Mega  298.246340\n",
       "4  15.0   8.437408      1.405998      Micro   56.594181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_01 = pd.read_csv(PATH + file_list[1])\n",
    "df_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "TV              0.999497\n",
      "Radio           0.869105\n",
      "Social_Media    0.528906\n",
      "Name: Sales, dtype: float64\n",
      "0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Social_Media    0.528906\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 결측값 : 26개\n",
    "print(df_01.isnull().sum().sum())\n",
    "# TV와 매출의 양의 상관관계가 있으며, 제일 높음.\n",
    "q1 = df_01.corr().abs().drop('Sales')['Sales']\n",
    "print(q1)\n",
    "print(round(q1.max(), 5))\n",
    "q1.argmax() # 최댓값의 위치정보\n",
    "q1.idxmax() # 최댓값의 id값\n",
    "q1.nlargest(1) # 최댓값의 id값과 최댓값 출력\n",
    "q1.argmin() # 최솟값의 위치정보\n",
    "q1.idxmin() # 최솟값의 위치정보\n",
    "q1.nsmallest(1) # 최솟값의 위치정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.56256963 -0.00397039  0.00496402]\n",
      "Sales~TV+Radio+Social_Media\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social_Media</th>\n",
       "      <th>Influencer</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>72.0</td>\n",
       "      <td>25.406596</td>\n",
       "      <td>3.215455</td>\n",
       "      <td>Micro</td>\n",
       "      <td>262.401171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.380311</td>\n",
       "      <td>5.286681</td>\n",
       "      <td>Mega</td>\n",
       "      <td>80.940725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>88.0</td>\n",
       "      <td>26.009640</td>\n",
       "      <td>1.495601</td>\n",
       "      <td>Nano</td>\n",
       "      <td>321.046689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>39.0</td>\n",
       "      <td>4.856123</td>\n",
       "      <td>0.874163</td>\n",
       "      <td>Macro</td>\n",
       "      <td>131.077255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>64.0</td>\n",
       "      <td>23.081488</td>\n",
       "      <td>3.056298</td>\n",
       "      <td>Macro</td>\n",
       "      <td>219.568184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>50.0</td>\n",
       "      <td>22.728177</td>\n",
       "      <td>3.794120</td>\n",
       "      <td>Mega</td>\n",
       "      <td>184.040212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>82.0</td>\n",
       "      <td>28.920430</td>\n",
       "      <td>3.213067</td>\n",
       "      <td>Micro</td>\n",
       "      <td>285.392143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>36.0</td>\n",
       "      <td>15.393056</td>\n",
       "      <td>3.601162</td>\n",
       "      <td>Nano</td>\n",
       "      <td>119.220715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>61.0</td>\n",
       "      <td>20.789544</td>\n",
       "      <td>2.473938</td>\n",
       "      <td>Macro</td>\n",
       "      <td>225.822151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>44.0</td>\n",
       "      <td>19.800072</td>\n",
       "      <td>5.096192</td>\n",
       "      <td>Micro</td>\n",
       "      <td>163.631457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV      Radio  Social_Media Influencer       Sales\n",
       "93    72.0  25.406596      3.215455      Micro  262.401171\n",
       "130   21.0   1.380311      5.286681       Mega   80.940725\n",
       "136   88.0  26.009640      1.495601       Nano  321.046689\n",
       "162   39.0   4.856123      0.874163      Macro  131.077255\n",
       "179   64.0  23.081488      3.056298      Macro  219.568184\n",
       "...    ...        ...           ...        ...         ...\n",
       "4433  50.0  22.728177      3.794120       Mega  184.040212\n",
       "4448  82.0  28.920430      3.213067      Micro  285.392143\n",
       "4452  36.0  15.393056      3.601162       Nano  119.220715\n",
       "4477  61.0  20.789544      2.473938      Macro  225.822151\n",
       "4569  44.0  19.800072      5.096192      Micro  163.631457\n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "q2 = df_01.dropna().copy()\n",
    "x_list = ['TV', 'Radio', 'Social_Media']\n",
    "lm = LinearRegression(fit_intercept=True).fit(q2[x_list], q2.Sales)\n",
    "print(lm.coef_)\n",
    "\n",
    "form1 = 'Sales~' + '+'.join(x_list) # 앞쪽변수가 종속변수, 뒤쪽 변수가 독립변수\n",
    "print(form1)\n",
    "# ols1 = ols(form1, data = q2) # 분리를 해줄 거면 변수를 따로 선언, 결과값만 볼꺼면 바로 fit을 해줘도 됨.\n",
    "# ols2 = ols1.fit()\n",
    "# dir(ols2)\n",
    "ols1 = ols(form1, data = q2).fit()\n",
    "# ols1.summary()\n",
    "(ols1.outlier_test()['unadj_p'] < 0.05).sum()\n",
    "q2[ols1.outlier_test()['unadj_p'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['long_hair', 'forehead_width_cm', 'forehead_height_cm', 'nose_wide',\n",
       "       'nose_long', 'lips_thin', 'distance_nose_to_lip_long', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_02 = pd.read_csv(PATH + file_list[3])\n",
    "df_02.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26449884843487076"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_list = ['forehead_width_cm', 'forehead_height_cm']\n",
    "df_02_01 = df_02[var_list].copy()\n",
    "df_02_01['forehead_ratio'] = df_02_01[var_list[0]] / df_02_01[var_list[1]]\n",
    "forehead_ratio_avg = df_02_01['forehead_ratio'].sum() / len(df_02_01)\n",
    "df_02_01['forehead_ratio_residual'] = [df_02_01['forehead_ratio'][i] - forehead_ratio_avg for i in range(len(df_02_01))]\n",
    "df_02_01['forehead_ratio_residual_square'] = [(df_02_01['forehead_ratio_residual'][i]**2) for i in range(len(df_02_01))]\n",
    "forehead_ratio_variance = df_02_01['forehead_ratio_residual_square'].sum() / len(df_02_01)\n",
    "forehead_ratio_variance**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.233618718921447 0.26452529699735255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>forehead_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      forehead_width_cm  forehead_height_cm  forehead_ratio\n",
       "1641               15.5                 5.1        3.039216\n",
       "1817               15.5                 5.1        3.039216\n",
       "4948               15.5                 5.1        3.039216"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_list = ['forehead_width_cm', 'forehead_height_cm']\n",
    "df_02_01 = df_02[var_list].copy()\n",
    "df_02_01['forehead_ratio'] = df_02_01[var_list[0]] / df_02_01[var_list[1]]\n",
    "xbar = (df_02_01['forehead_ratio']).mean()\n",
    "std = (df_02_01['forehead_ratio']).std()\n",
    "print(xbar, std)\n",
    "df_02_01[(df_02_01['forehead_ratio']) < xbar - (3*std)].sum() + df_02_01[(df_02_01['forehead_ratio']) > xbar + (3*std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female']\n",
      "2.4617792693952707e-48\n",
      "df_02_out.statistic : 2.9994984197511543 / df_02_out.pvalue : 0.0027186702390657176\n",
      "2.999499\n",
      "2.999498\n"
     ]
    }
   ],
   "source": [
    "print(df_02.gender.unique())\n",
    "df_02['forehead_ratio'] = df_02['forehead_width_cm'] / df_02['forehead_height_cm']\n",
    "gr_A = df_02[df_02.gender == 'Male']['forehead_ratio']\n",
    "gr_B = df_02[df_02.gender == 'Female']['forehead_ratio']\n",
    "\n",
    "from scipy.stats import bartlett, ttest_1samp, ttest_ind, ttest_rel\n",
    "## ttest-1samp 일표본\n",
    "## ttest-ind 독립인 이표본\n",
    "## ttest-rel 대응인 이표본\n",
    "\n",
    "bart1 = bartlett(gr_A, gr_B)\n",
    "print(bart1.pvalue) ## p-value가 0.05미만 귀무가설(분산에 차이가 없다) 기각 -> 이분산이다.\n",
    "\n",
    "df_02_out = ttest_ind(gr_A, gr_B, equal_var = False)\n",
    "print(f'df_02_out.statistic : {df_02_out.statistic} / df_02_out.pvalue : {df_02_out.pvalue}')\n",
    "\n",
    "round(abs(df_02_out.statistic), 3) # 3번째자리까지 남김(4번째자리에서 반올림)\n",
    "print(np.ceil(df_02_out.statistic * 1000000) / 1000000) # 올림 : 정수형태로 반환하기에 반드시 곱하기 후 같은 수로 나누어 줘야함\n",
    "print(np.floor(df_02_out.statistic * 1000000) / 1000000) # 내림 : 정수형태로 반환하기에 반드시 곱하기 후 같은 수로 나누어 줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "df_02 = pd.read_csv(PATH + file_list[3])\n",
    "x_list = ['long_hair', 'forehead_width_cm', 'forehead_height_cm', 'nose_wide','nose_long', 'lips_thin', 'distance_nose_to_lip_long']\n",
    "y_list = ['gender']\n",
    "df_02[y_list].value_counts()\n",
    "gender_dict = dict({'Male' : 0, 'Female' : 1})\n",
    "df_02['gender'] = df_02['gender'].apply(lambda x: gender_dict[x]) \n",
    "x_train, x_test, y_train, y_test = train_test_split(df_02[x_list], df_02[y_list], train_size = 0.7, test_size = 0.3, random_state = 123)\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.97      0.96      0.96       743\n",
      "        Male       0.96      0.97      0.97       758\n",
      "\n",
      "    accuracy                           0.97      1501\n",
      "   macro avg       0.97      0.97      0.97      1501\n",
      "weighted avg       0.97      0.97      0.97      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "x_list = ['long_hair', 'forehead_width_cm', 'forehead_height_cm', 'nose_wide','nose_long', 'lips_thin', 'distance_nose_to_lip_long']\n",
    "df_02 = pd.read_csv(PATH + file_list[3])\n",
    "df_train, df_test = train_test_split(df_02, train_size = 0.7, test_size = 0.3, random_state = 123)\n",
    "model = LogisticRegression().fit(df_train[x_list], df_train.gender)\n",
    "model.predict(df_test[x_list]) # 클래스명으로반환\n",
    "model.predict_proba(df_test[x_list]) # 가능성으로 반환\n",
    "\n",
    "from sklearn.metrics import precision_score, classification_report\n",
    "precision_score(df_test.gender, model.predict(df_test[x_list]), pos_label = 'Male') # 0.9596354166666666\n",
    "print(classification_report(df_test.gender, model.predict(df_test[x_list])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_03 = pd.read_csv(PATH + file_list[4])\n",
    "df_03_kor = df_03[df_03['LOCATION'] == 'KOR'].copy()\n",
    "round(pd.pivot_table(df_03_kor, index = 'TIME', values = 'Value', aggfunc = 'sum').reset_index().corr().TIME[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POULTRY': 0.4690625508910583}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_03_KJ = df_03[df_03.LOCATION.isin(['KOR', 'JPN'])]\n",
    "subject_list = df_03_KJ.SUBJECT.unique()\n",
    "\n",
    "# 대응 t테스트 H0 : 평균차이가 없다. H1 : 평균차이가 있다.\n",
    "from scipy.stats import ttest_rel\n",
    "ttest_sample = pd.pivot_table(df_03_KJ[df_03_KJ.SUBJECT == 'BEEF'], index = 'TIME', columns = 'LOCATION', values = 'Value').dropna()\n",
    "ttest_out = ttest_rel(ttest_sample.KOR, ttest_sample.JPN)\n",
    "p_value = ttest_out.pvalue\n",
    "\n",
    "subject_dict = dict()\n",
    "target_dict = dict()\n",
    "for SUBJECT in subject_list:\n",
    "    ttest_sample = pd.pivot_table(df_03_KJ[df_03_KJ.SUBJECT == SUBJECT], index = 'TIME', columns = 'LOCATION', values = 'Value').dropna()\n",
    "    ttest_out = ttest_rel(ttest_sample.KOR, ttest_sample.JPN)\n",
    "    p_value = ttest_out.pvalue\n",
    "    subject_dict[SUBJECT] = p_value\n",
    "    if p_value >= 0.05:\n",
    "        target_dict[SUBJECT] = p_value\n",
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_03_kor = df_03[df_03.LOCATION == 'KOR']\n",
    "subject_list = df_03_kor.SUBJECT.unique()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "temp = df_03_kor[df_03_kor.SUBJECT == 'BEEF']\n",
    "lm = LinearRegression().fit(temp[['TIME']], temp['Value']) # 반드시 2차식 구조로 넣어주어야 함.\n",
    "pred = lm.predict(temp[['TIME']])\n",
    "r2_score = lm.score(temp[['TIME']], temp[['Value']])\n",
    "\n",
    "# coef_dict = dict()\n",
    "# for SUBJECT in subject_list:\n",
    "#     temp = df_03_kor[df_03_kor.SUBJECT == SUBJECT]\n",
    "#     lm = LinearRegression().fit(temp[['TIME']], temp[['Value']]) # 반드시 2차식 구조로 넣어주어야 함.\n",
    "#     coef_dict[SUBJECT] = lm.coef_[0][0]\n",
    "# coef_dict\n",
    "\n",
    "mape_dict = dict()\n",
    "for SUBJECT in subject_list:\n",
    "    temp = df_03_kor[df_03_kor.SUBJECT == SUBJECT]\n",
    "    lm = LinearRegression().fit(temp[['TIME']], temp['Value']) # x값은 반드시 1차원으로 넣을 수 없음. y값은 상관없음\n",
    "    pred = lm.predict(temp[['TIME']])\n",
    "    r2_score = lm.score(temp[['TIME']], temp[['Value']])\n",
    "    mape = (abs(temp['Value'] - pred) / temp['Value']).sum() * 100 / len(temp)\n",
    "    mape_dict[SUBJECT] = mape, r2_score\n",
    "mape_dict\n",
    "pd.DataFrame(mape_dict,index = ['mape', 'r2_score']).T\n",
    "\n",
    "## 번외\n",
    "for SUBJECT in subject_list:\n",
    "    temp = df_03_kor[df_03_kor.SUBJECT == SUBJECT]\n",
    "    globals()['lm_'+ SUBJECT] = LinearRegression().fit(temp[['TIME']], temp['Value']) # x값은 반드시 1차원으로 넣을 수 없음. y값은 상관없음\n",
    "    pred = eval('lm'+ SUBJECT).predict(temp[['TIME']])\n",
    "    r2_score = lm.score(temp[['TIME']], temp[['Value']])\n",
    "    mape = (abs(temp['Value'] - pred) / temp['Value']).sum() * 100 / len(temp)\n",
    "    mape_dict[SUBJECT] = mape, r2_score\n",
    "# lm_BEEF의 방식으로 모델이 모두 저장되어 있음. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe3bab233825460445dbfeea6dcd52ef5815a3fa13c858fea07ac830aa383284"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
